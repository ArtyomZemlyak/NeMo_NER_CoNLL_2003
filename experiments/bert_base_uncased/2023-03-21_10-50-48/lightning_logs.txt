GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name                  | Type                 | Params
---------------------------------------------------------------
0 | bert_model            | BertEncoder          | 109 M 
1 | classifier            | TokenClassifier      | 594 K 
2 | loss                  | CrossEntropyLoss     | 0     
3 | classification_report | ClassificationReport | 0     
---------------------------------------------------------------
110 M     Trainable params
0         Non-trainable params
110 M     Total params
440.307   Total estimated model params size (MB)
`Trainer.fit` stopped: `max_epochs=5` reached.
Restoring states from the checkpoint path at experiments/bert_base_uncased/2023-03-21_10-50-48/checkpoints/bert_base_uncased--f1=95.8367-epoch=4.ckpt
Restored all states from the checkpoint file at experiments/bert_base_uncased/2023-03-21_10-50-48/checkpoints/bert_base_uncased--f1=95.8367-epoch=4.ckpt
