GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name                  | Type                 | Params
---------------------------------------------------------------
0 | bert_model            | RobertaEncoder       | 124 M 
1 | classifier            | TokenClassifier      | 594 K 
2 | loss                  | CrossEntropyLoss     | 0     
3 | classification_report | ClassificationReport | 0     
---------------------------------------------------------------
125 M     Trainable params
0         Non-trainable params
125 M     Total params
500.960   Total estimated model params size (MB)
`Trainer.fit` stopped: `max_epochs=5` reached.
Restoring states from the checkpoint path at experiments/roberta_base/2023-03-21_12-06-45/checkpoints/roberta_base--f1=96.6813-epoch=4.ckpt
Restored all states from the checkpoint file at experiments/roberta_base/2023-03-21_12-06-45/checkpoints/roberta_base--f1=96.6813-epoch=4.ckpt
