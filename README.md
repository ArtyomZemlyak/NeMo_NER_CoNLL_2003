# NER CoNLL-2003

Задача NER на CoNLL-2003 датасете.

## Подготовка датасета

1. Скрипт `load_conll_2003.sh` производит подгрузку датасета.
2. В нотебуке `explore_data.ipynb` производится исследование изначальных данных.
3. Скрипт `convert_for_nemo.py` производит перевод данных в формат, который подходит для тренировки NER через `NeMo`.

## Тренировка моделей

Для тренировки моделей используется скрипт `train.py` и определённый конфиг из папки `configs`:

### Bert Base Uncased

```python
python train.py \
    --config-path="./configs" \
    --config-name="train_bert_base_uncased.yaml"
```

| label        | precision | recall | f1    | support |
| ------------ | --------- | ------ | ----- | ------- |
| O            | 99.60     | 99.65  | 99.62 | 42744   |
| LOC          | 97.50     | 96.99  | 97.24 | 2090    |
| MISC         | 89.85     | 90.06  | 89.96 | 1268    |
| ORG          | 93.44     | 93.26  | 93.35 | 2092    |
| PER          | 99.17     | 98.85  | 99.01 | 3144    |
| ------------ | --------- | ------ | ----- | ------- |
| micro avg    | 98.99     | 98.99  | 98.99 | 51338   |
| macro avg    | 95.91     | 95.76  | 95.84 | 51338   |
| weighted avg | 98.99     | 98.99  | 98.99 | 51338   |

### RoBERTa Base

```python
python train.py \
    --config-path="./configs" \
    --config-name="train_roberta_base.yaml"
```

| label        | precision | recall | f1    | support |
| ------------ | --------- | ------ | ----- | ------- |
| O            | 99.81     | 99.77  | 99.79 | 42715   |
| LOC          | 96.56     | 96.79  | 96.68 | 2088    |
| MISC         | 93.67     | 93.38  | 93.52 | 1268    |
| ORG          | 95.49     | 95.17  | 95.33 | 2092    |
| PER          | 97.71     | 98.46  | 98.09 | 3125    |
| ------------ | --------- | ------ | ----- | ------- |
| micro avg    | 99.22     | 99.22  | 99.22 | 51288   |
| macro avg    | 96.65     | 96.71  | 96.68 | 51288   |
| weighted avg | 99.22     | 99.22  | 99.22 | 51288   |

### DeBERTa V3 Base

```python
python train.py \
    --config-path="./configs" \
    --config-name="train_deberta_v3_base.yaml"
```

| label        | precision | recall | f1    | support |
| ------------ | --------- | ------ | ----- | ------- |
| O            | 99.86     | 99.85  | 99.85 | 42759   |
| LOC          | 97.90     | 98.13  | 98.02 | 2091    |
| MISC         | 93.50     | 95.35  | 94.42 | 1268    |
| ORG          | 96.96     | 95.98  | 96.47 | 2092    |
| PER          | 99.14     | 99.02  | 99.08 | 3149    |
| ------------ | --------- | ------ | ----- | ------- |
| micro avg    | 99.46     | 99.46  | 99.46 | 51359   |
| macro avg    | 97.47     | 97.67  | 97.57 | 51359   |
| weighted avg | 99.46     | 99.46  | 99.46 | 51359   |

## Тестирование моделей

Тестирование модели на тестовом датасете с сохранением предсказаний для доп проверки.

### DeBERTa V3 Base тест

```python
python test.py \
    --config-path="./configs" \
    --config-name="train_deberta_v3_base.yaml" \
    +pretrained_model="experiments/deberta_v3_base/2023-03-21_13-16-01/checkpoints/deberta_v3_base.nemo" \
    exp_manager.create_clearml_logger=false
```

## Выводы

1. Датасет довольно плохо подготовлен.

   - Есть неправильная разметка. Статься для исправления: [Identifying Incorrect Labels in the CoNLL-2003 Corpus](https://aclanthology.org/2020.conll-1.16.pdf)
   - Много повторяющихся примеров
   - Изначальная разметка не подойдёт для `BIO` тегирования в связи с малым количеством `B-` тегов.

2. Выборо модели.

    - Смотрим на безлайн в виде трансформеров.
    - Для лучшей точности можно взять схожий домен для предопучения, например новости для conll.
    - В целом выбор модели напрямую зависит от базовых характеристик этой модели на NLP tasks. Что будет показано далее на результатах тренировки.

3. Результаты тренировки моделей.

    - Базовой BERT base uncased модели достаточно для получения приемлемого качества (`macro avg f1=95.84`).
    - Лучшая базовая модель - deberta_v3_base (`macro avg f1=97.57`).
    - Для тренировки моделей использовался `NeMo` фреймворк в связи с его удобством использования, настройки и воспроизводимости.
    - Для мониторинга экспериментов использовался self-hosted `ClearML` с интеграцией в `NeMo`. Мой [PR в NeMo](https://github.com/NVIDIA/NeMo/pull/6014)

4. Интерпретация результатов.

    - Первоначально смотрим на метрику `macro avg f1` как хорошо взвешенную относительно провисающих классов.
    - После `./explore_results.ipynb` видим, что основная проблема у модели с типом тега
    - И с совмещением типа тега и его границ
    - Но в целом качество хорошее
